{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limax = [200, 300, 10, 10, 45, 1, 0.18, 6, 2500, 0.08]\n",
    "limin =  [150, 220, 6, -10, 16, 0.5, 0.08, 2.5, 1700, 0.025]\n",
    "xnorm = myML.norm0to1_minmax(limax, limin)\n",
    "def weight(x_t):\n",
    "    Sw, Wfw, A, Lambda, q, lambda2, tc, Nz, Wdg, Wp = x_t\n",
    "    Lambda = Lambda/360*2*np.pi\n",
    "\n",
    "    w = 0.036*Sw**0.758*Wfw**0.0035*(A/(np.cos(Lambda)**2))**0.6*q**0.006*lambda2**0.04\n",
    "    w = w*(100*tc/np.cos(Lambda))**(-0.3)*(Nz*Wdg)**0.49+Sw*Wp\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrain = 80\n",
    "mcv = 10\n",
    "mtest = 10\n",
    "\n",
    "x_train = myML.staticSampling('LHS', d=10, npoints=mtrain)\n",
    "x_cv = myML.staticSampling('LHS', d=10, npoints=mcv)\n",
    "x_test = myML.staticSampling('LHS', d=10, npoints=mtest)\n",
    "\n",
    "y_train = np.array([weight(xnorm.recover(x_train))])\n",
    "y_cv = np.array([weight(xnorm.recover(x_cv))])\n",
    "y_test = np.array([weight(xnorm.recover(x_test))])\n",
    "\n",
    "ynorm = myML.norm0to1(np.concatenate((y_train, y_cv, y_test), axis=1))\n",
    "y_train = ynorm.normalize(y_train)\n",
    "y_cv = ynorm.normalize(y_cv)\n",
    "y_test = ynorm.normalize(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 150        #Times that the entire dataset is used to train the NN\n",
    "lr = 0.1            #Learning rate\n",
    "lambd = 0           #Regularization term\n",
    "activation = ['ReLU','ReLU']\n",
    "lossname = 'MSE'\n",
    "optimizer = 'GD'\n",
    "\n",
    "n = 22\n",
    "yplot_train = np.zeros(n)\n",
    "yplot_cv = np.zeros(n)\n",
    "times = 300\n",
    "aux_train = np.zeros(times)\n",
    "aux_cv = np.zeros(times)\n",
    "for i in range(1,n+1):\n",
    "    nodes = [10, i, 1]\n",
    "    print('Trying with '+str(i)+' nodes in the hidden layer')\n",
    "    for j in range(times):\n",
    "        neuralnetwork = myML.ANN(nodes, activation, lossname)\n",
    "        costs = neuralnetwork.train(x_train, y_train, epochs, optimizer, lr, lambd)\n",
    "        aux_train[j] = costs[epochs-1]\n",
    "\n",
    "        temp = neuralnetwork.test(x_cv)\n",
    "        aux_cv[j] = np.sum(neuralnetwork.loss(y_cv, temp))\n",
    "\n",
    "    yplot_train[i-1] = np.mean(aux_train)\n",
    "    yplot_cv[i-1] = np.mean(aux_cv)\n",
    "\n",
    "plt.plot(range(1,n+1),yplot_train,label='Training set error')\n",
    "plt.plot(range(1,n+1),yplot_cv,label='Validation set error')\n",
    "plt.xlabel('Nº of neurons in hidden layer')\n",
    "plt.ylabel('Cost function error')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(1,n+1),np.abs(yplot_train-yplot_cv))\n",
    "plt.xlabel('Nº of neurons in hidden layer')\n",
    "plt.ylabel('Jtrain - Jcv')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 6000      #Times that the entire dataset is used to train the NN\n",
    "lr = 0.1            #Learning rate\n",
    "lambd = 0           #Regularization term\n",
    "activation = ['ReLU','ReLU']\n",
    "lossname = 'MSE'\n",
    "optimizer = 'GD'\n",
    "nodes = [10, 10, 1]\n",
    "\n",
    "neuralnetwork = myML.ANN(nodes, activation, lossname)\n",
    "costs = neuralnetwork.train(x_train, y_train, epochs, optimizer, lr, lambd)\n",
    "print(costs[-1])\n",
    "plt.plot(range(epochs),costs)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Cost function error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = neuralnetwork.test(x_test)\n",
    "J = np.sum(neuralnetwork.loss(y_test, temp))\n",
    "print('Mean squared error of the test set: '+str(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN Prediction\n",
    "exampleindex = 2\n",
    "x = np.array([x_test[:,exampleindex]]).T\n",
    "y = np.array([y_test[:,exampleindex]])\n",
    "#temp = neuralnetwork.testwithplot(x, 1, nodes)\n",
    "temp = neuralnetwork.test(x)\n",
    "error = np.sum(neuralnetwork.loss(y, temp))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "print('Cost function value: '+str(error))\n",
    "print('Predicted value: '+str(ynorm.recover(temp)[0,0]))\n",
    "print('Real value: '+str(ynorm.recover(y)[0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit",
   "metadata": {
    "interpreter": {
     "hash": "b126237f7ca490168c753438f1a9290c28cbd925e59b6904365c99f1dc93c750"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
