{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submarine features generator (+tectonic faults model +submarine height model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "#Personal library for some machine learning alg. implementations\n",
    "import myML\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Input must be the heightmap with water colored black RGB(0,0,0)\n",
    "\n",
    "The algorithm takes exponentially longer to compute the bigger the sea gaps are. Trim them down if it's taking hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tectonic faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (sea=black) (RGB 0,0,0) image in grayscale mode\n",
    "imX = Image.open(r\"input files/heightmap.png\",\"r\").convert('L')\n",
    "display(imX.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing image to land>=129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imData = np.array(imX)\n",
    "temp = np.min(imData[imData>0]), np.max(imData)\n",
    "temp = ((imData-temp[0])/(temp[1]-temp[0])*96+129).astype(np.uint8)\n",
    "for y0 in range(imData.shape[0]):\n",
    "    for x0 in range(imData.shape[1]):\n",
    "        if imData[y0,x0]>0:\n",
    "            imData[y0,x0] = temp[y0,x0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building first two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiusFinder(x0, imData, minPoints, limitradius):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    y0 = 0\n",
    "    for r in range(10000):\n",
    "        xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "        ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "\n",
    "        count = len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])\n",
    "        \n",
    "        if count>minPoints:\n",
    "            temp.append(r)\n",
    "            break\n",
    "\n",
    "    for y0 in range(1,imData.shape[0]):\n",
    "        r = temp[y0-1]-1\n",
    "        if r>limitradius:\n",
    "            xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "            ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "            if len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])>minPoints:\n",
    "                temp.append(r)\n",
    "                continue\n",
    "        r+=1\n",
    "        xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "        ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "        if len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])>minPoints:\n",
    "            temp.append(r)\n",
    "            continue\n",
    "        else: temp.append(r+1)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "def inner_loop(x0, imData, adaptiveRadius, minPoints):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    res = np.sqrt(lims[0]**2+lims[1]**2)\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        radius = adaptiveRadius[y0,x0]\n",
    "        xlim = [max(0, x0-1-radius), min(lims[1]-1, x0+1+radius)]\n",
    "        ylim = [max(0, y0-1-radius), min(lims[0]-1, y0+1+radius)]\n",
    "        \n",
    "        temp2 = np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)\n",
    "        landcount = len(temp2[0])\n",
    "        watercount = (1+ylim[1]-ylim[0])*(1+xlim[1]-xlim[0])-landcount\n",
    "\n",
    "        ranges = ylim[1]-ylim[0], xlim[1]-xlim[0]\n",
    "        center = (y0-ylim[0])/ranges[0], (x0-xlim[0])/ranges[1]\n",
    "        xlist, ylist = temp2[1]/ranges[1], temp2[0]/ranges[0]\n",
    "\n",
    "        distances = np.linalg.norm([xlist-center[1],ylist-center[0]], axis=0)\n",
    "        nearest = np.argsort(distances)[1:minPoints+1]\n",
    "        mindist = np.sqrt(((xlist[nearest[1]]-center[1])*ranges[1])**2+((ylist[nearest[1]]-center[0])*ranges[0])**2)/res\n",
    "        heights = [imData[ylim[0]+temp2[0][index],xlim[0]+temp2[1][index]] for index in nearest]\n",
    "        x_train = np.concatenate(([watercount/(watercount+landcount), mindist], (xlist-center[1])[nearest], (ylist-center[0])[nearest], np.array(heights)))\n",
    "\n",
    "        temp.append([x_train])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent = 0\n",
    "divergent = 255\n",
    "water = 0\n",
    "minPoints = 10\n",
    "limitradius = (np.sqrt(minPoints)-1)/2\n",
    "\n",
    "imData = np.array(imX)\n",
    "adaptiveRadius = np.zeros_like(imX)\n",
    "result = Parallel(n_jobs=-2)(delayed(radiusFinder)(x0, imData, minPoints, limitradius) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "adaptiveRadius = np.array(result).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(x0, imData, adaptiveRadius, minPoints) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "x_test = np.zeros((imData.shape[0]*imData.shape[1],minPoints*3+2))\n",
    "\n",
    "count = 0\n",
    "for x0 in result:\n",
    "    for elem in x0:\n",
    "        x_test[count,:] = elem[0]\n",
    "        count+=1\n",
    "\n",
    "x_test = pd.DataFrame(x_test,columns=['Water percent','Mindist']+[f'x{i}' for i in range(minPoints)]+[f'y{i}' for i in range(minPoints)]+[f'h{i}' for i in range(minPoints)])\n",
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnetwork = myML.ANN()\n",
    "neuralnetwork.loadClass(name=\"training/faultmodel\")\n",
    "#neuralnetwork.defineNorm('Input', maximum=x_test.max(), minimum=x_test.min())\n",
    "\n",
    "im = np.array(imX.copy())\n",
    "points = neuralnetwork.run(x_test)\n",
    "count = 0\n",
    "for x in range(im.shape[1]):\n",
    "    for y in range(im.shape[0]):\n",
    "        temp = np.argmax(points[count,:])\n",
    "        if temp==0: #Convergent\n",
    "            im[y,x] = 0\n",
    "        elif temp==1: #Divergent\n",
    "            im[y,x] = 255\n",
    "        else: im[y,x] = 128\n",
    "        count+=1\n",
    "\n",
    "im = Image.fromarray(im)\n",
    "im.save('output files/step1.png')\n",
    "display(im.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(x0, imData, faults, water, radius):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        if imData[y0,x0]!=water: \n",
    "            temp.append([False])\n",
    "            continue\n",
    "\n",
    "        xlim = [max(0, x0-1-radius), min(lims[1]-1, x0+1+radius)]\n",
    "        ylim = [max(0, y0-1-radius), min(lims[0]-1, y0+1+radius)]\n",
    "\n",
    "        faulty = faults[ylim[0]:ylim[1]+1,xlim[0]:xlim[1]+1]\n",
    "        x_train = [np.mean(faulty), np.std(faulty)]\n",
    "\n",
    "        temp.append([x_train])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = 0\n",
    "faults = np.array(im)/255\n",
    "\n",
    "radius = int(np.ceil(np.sqrt(minPoints)))\n",
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(x0, imData, faults, water, radius) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "x2_test = np.zeros((imData.shape[0]*imData.shape[1],2))\n",
    "count = 0\n",
    "count2 = 0\n",
    "index = []\n",
    "for x0 in result:\n",
    "    for elem in x0:\n",
    "        if elem[0] is not False:\n",
    "            x2_test[count2,:] = elem[0]\n",
    "            index.append(count)\n",
    "            count2+=1\n",
    "        count+=1\n",
    "\n",
    "x2_test2 = x_test.loc[x_test.index.isin(index)].reset_index(drop=True)\n",
    "x2_test2.insert(0,'Fault mean', x2_test[index,0]), x2_test2.insert(1,'Fault std', x2_test[index,1])\n",
    "x2_test2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnetwork = myML.ANN()\n",
    "neuralnetwork.loadClass(name=\"training/heightmodel\")\n",
    "\n",
    "fullHeightmap = imData.copy()\n",
    "points = neuralnetwork.run(x2_test2)\n",
    "count = 0\n",
    "for x in range(fullHeightmap.shape[1]):\n",
    "    for y in range(fullHeightmap.shape[0]):\n",
    "        if imData[y,x]!=water: \n",
    "            fullHeightmap[y,x] = np.uint8(imData[y,x]/255*128+127)#imData[y,x]\n",
    "            continue\n",
    "        fullHeightmap[y,x] = points[count,0]\n",
    "        count+=1\n",
    "\n",
    "imDepth = Image.fromarray(fullHeightmap)\n",
    "imDepth.save('output files/step2.png')\n",
    "display(imDepth.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def peakFinder(x0, imData):\n",
    "#     temp = []\n",
    "#     lims = imData.shape\n",
    "#     for y0 in range(imData.shape[0]):\n",
    "#         xlim = [max(0, x0-1), min(lims[1]-1, x0+1)]\n",
    "#         ylim = [max(0, y0-1), min(lims[0]-1, y0+1)]\n",
    "\n",
    "#         color = imData[y0,x0]\n",
    "#         color = color-2 if color<127 else color*0.99\n",
    "\n",
    "#         count = len(np.where(imData[ylim[0]:ylim[1]+1,xlim[0]:xlim[1]+1]>color)[0])\n",
    "#         if count<=2.2: temp.append(255)\n",
    "#         else: temp.append(0)\n",
    "\n",
    "#     return temp\n",
    "\n",
    "# heighttemp = np.array(Image.fromarray(fullHeightmap).resize((600,300)))\n",
    "# peakData = np.empty_like(heighttemp)\n",
    "# result = Parallel(n_jobs=-2)(delayed(peakFinder)(x0, heighttemp) for x0 in tqdm(range(heighttemp.shape[1])))\n",
    "\n",
    "# for x0, res in enumerate(result):\n",
    "#     for y0, value in enumerate(res):\n",
    "#         peakData[y0,x0] = value\n",
    "\n",
    "# Image.fromarray(peakData).save('output files/step3.png')\n",
    "# display(Image.fromarray(peakData).resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakFinder(x0, imData):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        color = imData[y0,x0]\n",
    "        if color>=127:\n",
    "            temp.append(255)\n",
    "            continue\n",
    "\n",
    "        count = 0\n",
    "        sum = []\n",
    "        for x1 in range(-1,2,1):\n",
    "            x2 = x0+x1\n",
    "            if x2<0 or x2>=lims[1]: continue\n",
    "            for y1 in range(-1,2,1):\n",
    "                if x1==0 and y1==0: continue\n",
    "                y2 = y0+y1\n",
    "                if y2<0 or y2>=lims[0]: continue\n",
    "                sum.append(imData[y2,x2])\n",
    "\n",
    "        if np.std(sum)>3: temp.append(255)\n",
    "        else: temp.append(0)\n",
    "\n",
    "    return temp\n",
    "\n",
    "heighttemp = np.array(Image.fromarray(fullHeightmap).resize((1200,600)))\n",
    "peakData = np.empty_like(heighttemp)\n",
    "result = Parallel(n_jobs=-2)(delayed(peakFinder)(x0, heighttemp) for x0 in tqdm(range(heighttemp.shape[1])))\n",
    "\n",
    "for x0, res in enumerate(result):\n",
    "    for y0, value in enumerate(res):\n",
    "        peakData[y0,x0] = value\n",
    "\n",
    "Image.fromarray(peakData).save('output files/step3.png')\n",
    "display(Image.fromarray(peakData).resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion through Diffusion Limited Aggregation [with GPU nVidia and corresponding packages installed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def graphIterationKernel(nGlobal, ylim, xlim, iters):\n",
    "#     @cuda.jit\n",
    "#     def f(peaks, depths, seeds, randomMovements):\n",
    "#         pos = cuda.grid(1)\n",
    "        \n",
    "#         if pos < nGlobal: # Must have or it crashes\n",
    "\n",
    "#             y0, x0 = seeds[pos]\n",
    "            \n",
    "#             for x1 in range(-1,2,1):\n",
    "#                 x2 = x0+x1\n",
    "#                 if x2<0 or x2>=xlim: continue\n",
    "#                 for y1 in range(-1,2,1):\n",
    "#                     if x1==0 and y1==0: continue\n",
    "#                     y2 = y0+y1\n",
    "#                     if y2<0 or y2>=ylim: continue\n",
    "#                     if peaks[y2,x2] < 255: return\n",
    "\n",
    "#             for i in range(iters):\n",
    "#                 movement = randomMovements[i]\n",
    "#                 if movement==0:\n",
    "#                     y0 -= 1\n",
    "#                     x0 -= 1\n",
    "#                 elif movement==1:\n",
    "#                     y0 -= 1\n",
    "#                 elif movement==1:\n",
    "#                     y0 -= 1\n",
    "#                     x0 += 1\n",
    "#                 elif movement==1:\n",
    "#                     x0 -= 1\n",
    "#                 elif movement==1:\n",
    "#                     x0 += 1\n",
    "#                 elif movement==1:\n",
    "#                     y0 += 1\n",
    "#                     x0 -= 1\n",
    "#                 elif movement==1:\n",
    "#                     y0 += 1\n",
    "#                 elif movement==1:\n",
    "#                     y0 += 1\n",
    "#                     x0 += 1\n",
    "\n",
    "#                 for x1 in range(-1,2,1):\n",
    "#                     x2 = x0+x1\n",
    "#                     if x2<0 or x2>=xlim: continue\n",
    "#                     for y1 in range(-1,2,1):\n",
    "#                         if x1==0 and y1==0: continue\n",
    "#                         y2 = y0+y1\n",
    "#                         if y2<0 or y2>=ylim: continue\n",
    "#                         if peaks[y2,x2] < 255:\n",
    "#                             peaks[y0,x0] = \n",
    "\n",
    "            \n",
    "                \n",
    "\n",
    "#     return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion through Diffusion Limited Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def peakFinder(pos, fullHeightmap, simState):\n",
    "#     lims = simState.shape\n",
    "    \n",
    "#     ydown, yup = [max(0, pos[0]-1), min(lims[0]-1, pos[0]+1)]\n",
    "#     xdown, xup = [max(0, pos[1]-1), min(lims[1]-1, pos[1]+1)]\n",
    "#     #Check boundary for seed\n",
    "#     if np.max(simState[ydown:yup+1,xdown:xup+1])>0: return [True, pos]\n",
    "\n",
    "#     weights = [fullHeightmap[yup,x0]+1,fullHeightmap[y0,xup]+1,fullHeightmap[ydown,x0]+1,fullHeightmap[y0,xdown]+1]\n",
    "#     paths = random.choices([0,1,2,3], weights=weights)[0]\n",
    "\n",
    "#     if paths==0: pos[0] = yup\n",
    "#     elif paths==1: pos[1] = xup\n",
    "#     elif paths==2: pos[0] = ydown\n",
    "#     else: pos[1] = xdown\n",
    "#     return [False, pos]\n",
    "\n",
    "# maxiter = 1000\n",
    "# lookupRadius = 2\n",
    "# diffused = peakData.copy()\n",
    "\n",
    "# temp = np.where(diffused==0)\n",
    "# total, voids, count = heighttemp.shape[0]*heighttemp.shape[1], len(temp[0]), heighttemp.shape[0]*heighttemp.shape[1]-len(temp[0])\n",
    "# particles = int(np.sqrt(voids)*100)\n",
    "# threshold1, threshold2 = int(np.sqrt(voids)*16), int(np.sqrt(voids)*4)\n",
    "# nparticles = particles\n",
    "# points = np.random.randint(0, voids, particles)\n",
    "# points = [[temp[0][x],temp[1][x]] for x in points]\n",
    "\n",
    "# bar_format='{desc}: |{bar}| {n_fmt}/{total_fmt} [t-{elapsed}, {postfix}]'\n",
    "# pbar = tqdm(range(1,maxiter), desc='DLA', bar_format=bar_format)\n",
    "\n",
    "# with Parallel(n_jobs=-2) as parallel:\n",
    "#     for k in pbar:\n",
    "#         if nparticles<20000:\n",
    "#             result = []\n",
    "#             for i in range(nparticles):\n",
    "#                 result.append(peakFinder(points[i], fullHeightmap, diffused))\n",
    "#         else:\n",
    "#             result = parallel(delayed(peakFinder)(points[i], fullHeightmap, diffused) for i in range(nparticles))\n",
    "\n",
    "#         points = []\n",
    "#         naggregated = count\n",
    "#         temp = int(255*(1-(count/total)**(1/4)))\n",
    "#         for i,elem in enumerate(result):\n",
    "#             flag, pos = elem\n",
    "#             if flag is True:\n",
    "#                 if diffused[pos[0],pos[1]]==0:\n",
    "#                     count+=1\n",
    "#                     diffused[pos[0],pos[1]] = temp\n",
    "#             else: points.append(pos)\n",
    "\n",
    "#         naggregated = count-naggregated\n",
    "#         nparticles = len(points)\n",
    "#         if nparticles<threshold1:\n",
    "#             temp = np.where(diffused==0)\n",
    "#             if len(temp[0]>threshold2):\n",
    "#                 points.extend([[temp[0][x],temp[1][x]] for x in np.random.randint(0, len(temp[0]), threshold2)])\n",
    "#                 nparticles+=threshold2\n",
    "#         pbar.set_postfix_str(f'nparticles: {nparticles}, naggregated: {naggregated}, completion %%: {count/total*100:.2f}')\n",
    "#         if nparticles==0: break\n",
    "    \n",
    "# random.seed()\n",
    "\n",
    "# # Application of gaussian blur with different radius to the diffused map + sum and normalization of the images\n",
    "# blur_radius = [2,8,16,32,64]\n",
    "# temp = sum([ndimage.gaussian_filter(diffused, sigma=r)/len(blur_radius) for r in blur_radius])\n",
    "# diffused = np.round((temp-np.min(temp))*255/(np.max(temp)-np.min(temp))).astype(np.uint8)\n",
    "# diffused = np.array(Image.fromarray(diffused).resize(imX.size, Image.Resampling.LANCZOS))\n",
    "# Image.fromarray(diffused).save('output files/step4.png')\n",
    "# display(Image.fromarray(diffused).resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakFinder(pos, fullHeightmap, simState):\n",
    "    lims = simState.shape\n",
    "    \n",
    "    ydown, yup = max(0, pos[0]-1), min(lims[0]-1, pos[0]+1)\n",
    "    xdown, xup = max(0, pos[1]-1), min(lims[1]-1, pos[1]+1)\n",
    "\n",
    "    # Check boundary for seed\n",
    "    if np.max(simState[ydown:yup+1, xdown:xup+1]) > 0:\n",
    "        return [True, pos]\n",
    "\n",
    "    # Ensure correct indexing\n",
    "    y0, x0 = pos[0], pos[1]\n",
    "    weights = [\n",
    "        fullHeightmap[yup, x0] + 1,\n",
    "        fullHeightmap[y0, xup] + 1,\n",
    "        fullHeightmap[ydown, x0] + 1,\n",
    "        fullHeightmap[y0, xdown] + 1\n",
    "    ]\n",
    "    if sum(weights) == 0: weights = [1, 1, 1, 1]\n",
    "    paths = random.choices([0, 1, 2, 3], weights=weights)[0]\n",
    "\n",
    "    if paths == 0:\n",
    "        pos[0] = yup\n",
    "    elif paths == 1:\n",
    "        pos[1] = xup\n",
    "    elif paths == 2:\n",
    "        pos[0] = ydown\n",
    "    else:\n",
    "        pos[1] = xdown\n",
    "\n",
    "    return [False, pos]\n",
    "\n",
    "# Simulation parameters\n",
    "maxiter = 1000\n",
    "lookupRadius = 2\n",
    "\n",
    "diffused = peakData.copy()\n",
    "\n",
    "# Get initial void positions\n",
    "temp = np.where(diffused == 0)\n",
    "total = diffused.shape[0] * diffused.shape[1]\n",
    "voids = len(temp[0])\n",
    "count = total - voids\n",
    "\n",
    "particles = int(np.sqrt(voids) * 100)\n",
    "threshold1, threshold2 = int(np.sqrt(voids) * 16), int(np.sqrt(voids) * 4)\n",
    "nparticles = particles\n",
    "\n",
    "points = np.random.randint(0, voids, particles)\n",
    "points = [[temp[0][x], temp[1][x]] for x in points]\n",
    "\n",
    "# Progress bar\n",
    "bar_format = '{desc}: |{bar}| {n_fmt}/{total_fmt} [t-{elapsed}, {postfix}]'\n",
    "pbar = tqdm(range(1, maxiter), desc='DLA', bar_format=bar_format)\n",
    "\n",
    "with Parallel(n_jobs=-2) as parallel:\n",
    "    for k in pbar:\n",
    "        if nparticles < 20000:\n",
    "            result = [peakFinder(points[i], fullHeightmap, diffused) for i in range(nparticles)]\n",
    "        else:\n",
    "            result = parallel(delayed(peakFinder)(points[i], fullHeightmap, diffused) for i in range(nparticles))\n",
    "\n",
    "        points = []\n",
    "        naggregated = count\n",
    "        temp_val = int(255 * (1 - (count / total) ** (1 / 4)))\n",
    "\n",
    "        for flag, pos in result:\n",
    "            if flag:\n",
    "                if diffused[pos[0], pos[1]] == 0:\n",
    "                    if count < total: count += 1\n",
    "                    diffused[pos[0], pos[1]] = temp_val\n",
    "            else:\n",
    "                points.append(pos)\n",
    "\n",
    "        naggregated = count - naggregated\n",
    "        nparticles = len(points)\n",
    "\n",
    "        if nparticles < threshold1:\n",
    "            temp = np.where(diffused == 0)\n",
    "            if len(temp[0]) > threshold2:\n",
    "                points.extend([[temp[0][x], temp[1][x]] for x in np.random.randint(0, len(temp[0]), threshold2)])\n",
    "                nparticles += threshold2\n",
    "\n",
    "        pbar.set_postfix_str(f'nparticles: {nparticles}, naggregated: {naggregated}, completion %: {count/total*100:.2f}')\n",
    "        if nparticles == 0:\n",
    "            break\n",
    "\n",
    "# Gaussian blur application\n",
    "blur_radius = [2, 8, 16, 32, 64]\n",
    "temp = sum([ndimage.gaussian_filter(diffused, sigma=r) / len(blur_radius) for r in blur_radius])\n",
    "\n",
    "diffused = np.round((temp - np.min(temp)) * 255 / (np.max(temp) - np.min(temp))).astype(np.uint8)\n",
    "\n",
    "diffused = np.array(Image.fromarray(diffused).resize(imX.size, Image.Resampling.LANCZOS))\n",
    "Image.fromarray(diffused).save('output files/step4.png')\n",
    "display(Image.fromarray(diffused).resize((1200, 600), Image.Resampling.NEAREST))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur_radius = [2, 8, 16, 32, 64]\n",
    "temp = sum([ndimage.gaussian_filter(diffused, sigma=r) / len(blur_radius) for r in blur_radius])\n",
    "\n",
    "diffused = np.round((temp - np.min(temp)) * 255 / (np.max(temp) - np.min(temp))).astype(np.uint8)\n",
    "\n",
    "diffused = np.array(Image.fromarray(diffused).resize(imX.size, Image.Resampling.LANCZOS))\n",
    "Image.fromarray(diffused).save('output files/step4.png')\n",
    "display(Image.fromarray(diffused).resize((1200, 600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, parameter):\n",
    "    return 1/(1+np.exp(-parameter*float(x-128)))\n",
    "\n",
    "parameter = 0.018\n",
    "\n",
    "erodedData = np.multiply(fullHeightmap,np.vectorize(func)(diffused, parameter)).astype(np.uint8)\n",
    "lims = np.min(erodedData[imData==0]), np.max(erodedData[imData==0]), np.min(erodedData[imData!=0]), np.max(erodedData[imData!=0])\n",
    "def func(x, y, a, b, c, d):\n",
    "    if y==0:\n",
    "        return 127*((x-a)/(b-a))\n",
    "    else:\n",
    "        return 128+127*((x-c)/(d-c))**2\n",
    "erodedData = np.round(np.vectorize(func)(erodedData, imData, lims[0],lims[1],lims[2],lims[3])).astype(np.uint8)\n",
    "blur_radius = [2,3,4]\n",
    "temp = sum([ndimage.gaussian_filter(erodedData, sigma=r)/len(blur_radius) for r in blur_radius])\n",
    "erodedData = np.round(temp).astype(np.uint8)\n",
    "display(Image.fromarray(erodedData).resize((1200,600), Image.Resampling.NEAREST))\n",
    "Image.fromarray(erodedData).save('output files/step5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watercolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If importing map with bathymetry (0-127 water, 128-255 land)\n",
    "# erodedData = np.array(Image.open(r\"input files/bathymetry.png\",\"r\").convert('L'))#.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(y0,erodedData,waterlims,landlims,northLat,temperate_center,artic_center,intermediate,m):\n",
    "    temp2 = []\n",
    "    equator_distance = abs(m*(y0/erodedData.shape[0])+northLat)+np.random.random()*0.01 #0 if at equator, northlat if at the poles \n",
    "    for x0 in range(erodedData.shape[1]):\n",
    "        height = erodedData[y0,x0]\n",
    "        \n",
    "        if height>=128: height = 255-min(height,135)\n",
    "        if True:#height<128:\n",
    "            # Sea\n",
    "            height = height if height<waterlims[3] else waterlims[3]\n",
    "            equatormodifier = (1-equator_distance*0.7)**2\n",
    "            if equator_distance<intermediate: \n",
    "                red = 0\n",
    "            else:\n",
    "                red = int(20*(equator_distance-intermediate)/(0.5-intermediate))\n",
    "\n",
    "            mingB = 0.73-0.17*equator_distance/0.5\n",
    "            max1gB = 1\n",
    "            max2gB = 1.25-0.25*(equator_distance/0.5)\n",
    "            minmod = 60-18*equator_distance/0.5\n",
    "            max1mod = 97-28*equator_distance/0.5\n",
    "            max2mod = 135-50*(equator_distance/0.5)\n",
    "\n",
    "            if height<=waterlims[1]:\n",
    "                modifier = ((height-waterlims[0])/(waterlims[1]-waterlims[0]))**2*0.5\n",
    "                heightmod = minmod+(max1mod-minmod)*modifier\n",
    "                gb = mingB+(max1gB-mingB)*modifier\n",
    "            elif height<=waterlims[2]:\n",
    "                modifier = ((height-waterlims[1])/(waterlims[2]-waterlims[1]))*0.5+0.5\n",
    "                heightmod = minmod+(max1mod-minmod)*modifier\n",
    "                gb = mingB+(max1gB-mingB)*modifier\n",
    "            else:\n",
    "                modifier = ((height-waterlims[2])/(waterlims[3]-waterlims[2]))\n",
    "                heightmod = max1mod+(max2mod-max1mod)*modifier\n",
    "                gb = max1gB+(max2gB-max1gB)*modifier\n",
    "            \n",
    "            blue = int(np.sqrt((heightmod**2-red**2)/(gb**2+1)))\n",
    "            green = int(gb*blue*equatormodifier)\n",
    "        # else:\n",
    "        #     # Land\n",
    "        #     height = height if height>landlims[0]+1 else landlims[0]+1\n",
    "        #     height = height if height<landlims[1] else landlims[1]\n",
    "        #     if equator_distance<artic_center: \n",
    "        #         red = int(50*(artic_center-equator_distance)/artic_center)\n",
    "        #     else:\n",
    "        #         red = 0\n",
    "        #     if equator_distance<=temperate_center:\n",
    "        #         temp = equator_distance/temperate_center\n",
    "        #         blue = 0\n",
    "        #         minmod = 56\n",
    "        #     else:\n",
    "        #         temp = (equator_distance-temperate_center)/(0.5-temperate_center)\n",
    "        #         blue = 74*temp\n",
    "        #         minmod = 56+35*temp\n",
    "            \n",
    "        #     maxmod = 77+49*equator_distance/0.5\n",
    "\n",
    "        #     modifier = ((height-landlims[0])/(landlims[1]-landlims[0]))**0.5\n",
    "        #     heightmod = minmod+(maxmod-minmod)*modifier\n",
    "        #     green = int(np.sqrt(heightmod**2-blue**2-red**2))\n",
    "        #     blue = int(blue)\n",
    "        temp2.append([red, green, blue])\n",
    "    return temp2\n",
    "\n",
    "equator = 0.680 #If 0 is the top, 1 the bottom, where is the equator in your map? The equation for m works with equator = 0, 0.5 or 1. ABW -> 0.547\n",
    "northLat = 0.389 #0.5 if the northernmost part of the image is the north pole. In ABW for example, the top of the image is at 70 degrees of latitude, so 70/90*0.5 = 0.389\n",
    "temperate_center = 0.187 #If 0 is the equator, 0.5 the north pole. You want this between Gibraltar and the Pirinees, or equivalent in your mod. ABW -> 0.187\n",
    "artic_center = 0.30 #If 0 is the equator, 0.5 the north pole. You want this around Helsinki in Finland, or equivalent in your mod. ABW -> 0.33\n",
    "\n",
    "temp = np.mean(erodedData[erodedData<128]), np.std(erodedData[erodedData<128])\n",
    "waterlims = np.min(erodedData[erodedData<128]), np.percentile(erodedData[erodedData<128],80), np.percentile(erodedData[erodedData<128],96),min(np.max(erodedData[erodedData<128]),127)\n",
    "temp = np.mean(erodedData[erodedData>127]), np.std(erodedData[erodedData>127])\n",
    "landlims = max(np.min(erodedData[erodedData>127]),128),np.max(erodedData[erodedData>127])\n",
    "\n",
    "m = -northLat/equator if equator != 0 else -1\n",
    "intermediate = (artic_center+temperate_center)/2\n",
    "watercolor = np.stack((erodedData.copy(),)*3, axis=-1)\n",
    "\n",
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(y0,erodedData,waterlims,landlims,northLat,temperate_center,artic_center,intermediate,m) for y0 in tqdm(range(erodedData.shape[0])))\n",
    "\n",
    "for y0, res in enumerate(result):\n",
    "    for x0, value in enumerate(res):\n",
    "        watercolor[y0,x0,:] = value\n",
    "\n",
    "    \n",
    "display(Image.fromarray(watercolor).resize((1200,600), Image.Resampling.NEAREST))\n",
    "Image.fromarray(watercolor).save('output files/watercolor_rgb_waterspec_a.png')\n",
    "print('Remember to convert it to dds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "watercolor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
