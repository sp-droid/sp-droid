{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submarine features generator (+tectonic faults model +submarine height model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "#Personal library for some machine learning alg. implementations\n",
    "import myML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "Input must be the heightmap with water colored black RGB(0,0,0)\n",
    "\n",
    "The algorithm takes exponentially longer to compute the bigger the sea gaps are. Trim them down if it's taking hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tectonic faults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load (sea=black) (RGB 0,0,0) image in grayscale mode\n",
    "imX = Image.open(r\"input files/heightmap.png\",\"r\").convert('L')\n",
    "display(imX.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing image to land>=129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imData = np.array(imX)\n",
    "temp = np.min(imData[imData>0]), np.max(imData)\n",
    "temp = ((imData-temp[0])/(temp[1]-temp[0])*96+129).astype(np.uint8)\n",
    "for y0 in range(imData.shape[0]):\n",
    "    for x0 in range(imData.shape[1]):\n",
    "        if imData[y0,x0]>0:\n",
    "            imData[y0,x0] = temp[y0,x0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building first two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radiusFinder(x0, imData, minPoints, limitradius):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    y0 = 0\n",
    "    for r in range(10000):\n",
    "        xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "        ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "\n",
    "        count = len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])\n",
    "        \n",
    "        if count>minPoints:\n",
    "            temp.append(r)\n",
    "            break\n",
    "\n",
    "    for y0 in range(1,imData.shape[0]):\n",
    "        r = temp[y0-1]-1\n",
    "        if r>limitradius:\n",
    "            xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "            ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "            if len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])>minPoints:\n",
    "                temp.append(r)\n",
    "                continue\n",
    "        r+=1\n",
    "        xlim = [max(0, x0-r), min(lims[1]-1, x0+r)]\n",
    "        ylim = [max(0, y0-r), min(lims[0]-1, y0+r)]\n",
    "        if len(np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)[0])>minPoints:\n",
    "            temp.append(r)\n",
    "            continue\n",
    "        else: temp.append(r+1)\n",
    "        \n",
    "    return temp\n",
    "\n",
    "def inner_loop(x0, imData, adaptiveRadius, minPoints):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    res = np.sqrt(lims[0]**2+lims[1]**2)\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        radius = adaptiveRadius[y0,x0]\n",
    "        xlim = [max(0, x0-1-radius), min(lims[1]-1, x0+1+radius)]\n",
    "        ylim = [max(0, y0-1-radius), min(lims[0]-1, y0+1+radius)]\n",
    "        \n",
    "        temp2 = np.where(imData[ylim[0]:ylim[1]+1, xlim[0]:xlim[1]+1]>0)\n",
    "        landcount = len(temp2[0])\n",
    "        watercount = (1+ylim[1]-ylim[0])*(1+xlim[1]-xlim[0])-landcount\n",
    "\n",
    "        ranges = ylim[1]-ylim[0], xlim[1]-xlim[0]\n",
    "        center = (y0-ylim[0])/ranges[0], (x0-xlim[0])/ranges[1]\n",
    "        xlist, ylist = temp2[1]/ranges[1], temp2[0]/ranges[0]\n",
    "\n",
    "        distances = np.linalg.norm([xlist-center[1],ylist-center[0]], axis=0)\n",
    "        nearest = np.argsort(distances)[1:minPoints+1]\n",
    "        mindist = np.sqrt(((xlist[nearest[1]]-center[1])*ranges[1])**2+((ylist[nearest[1]]-center[0])*ranges[0])**2)/res\n",
    "        heights = [imData[ylim[0]+temp2[0][index],xlim[0]+temp2[1][index]] for index in nearest]\n",
    "        x_train = np.concatenate(([watercount/(watercount+landcount), mindist], (xlist-center[1])[nearest], (ylist-center[0])[nearest], np.array(heights)))\n",
    "\n",
    "        temp.append([x_train])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convergent = 0\n",
    "divergent = 255\n",
    "water = 0\n",
    "minPoints = 10\n",
    "limitradius = (np.sqrt(minPoints)-1)/2\n",
    "\n",
    "imData = np.array(imX)\n",
    "adaptiveRadius = np.zeros_like(imX)\n",
    "result = Parallel(n_jobs=-2)(delayed(radiusFinder)(x0, imData, minPoints, limitradius) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "adaptiveRadius = np.array(result).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(x0, imData, adaptiveRadius, minPoints) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "x_test = np.zeros((imData.shape[0]*imData.shape[1],minPoints*3+2))\n",
    "\n",
    "count = 0\n",
    "for x0 in result:\n",
    "    for elem in x0:\n",
    "        x_test[count,:] = elem[0]\n",
    "        count+=1\n",
    "\n",
    "x_test = pd.DataFrame(x_test,columns=['Water percent','Mindist']+[f'x{i}' for i in range(minPoints)]+[f'y{i}' for i in range(minPoints)]+[f'h{i}' for i in range(minPoints)])\n",
    "x_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnetwork = myML.ANN()\n",
    "neuralnetwork.loadClass(name=\"training/faultmodel\")\n",
    "#neuralnetwork.defineNorm('Input', maximum=x_test.max(), minimum=x_test.min())\n",
    "\n",
    "im = np.array(imX.copy())\n",
    "points = neuralnetwork.run(x_test)\n",
    "count = 0\n",
    "for x in range(im.shape[1]):\n",
    "    for y in range(im.shape[0]):\n",
    "        temp = np.argmax(points[count,:])\n",
    "        if temp==0: #Convergent\n",
    "            im[y,x] = 0\n",
    "        elif temp==1: #Divergent\n",
    "            im[y,x] = 255\n",
    "        else: im[y,x] = 128\n",
    "        count+=1\n",
    "\n",
    "im = Image.fromarray(im)\n",
    "im.save('output files/step1.png')\n",
    "display(im.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sea depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(x0, imData, faults, water, radius):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        if imData[y0,x0]!=water: \n",
    "            temp.append([False])\n",
    "            continue\n",
    "\n",
    "        xlim = [max(0, x0-1-radius), min(lims[1]-1, x0+1+radius)]\n",
    "        ylim = [max(0, y0-1-radius), min(lims[0]-1, y0+1+radius)]\n",
    "\n",
    "        faulty = faults[ylim[0]:ylim[1]+1,xlim[0]:xlim[1]+1]\n",
    "        x_train = [np.mean(faulty), np.std(faulty)]\n",
    "\n",
    "        temp.append([x_train])\n",
    "\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water = 0\n",
    "faults = np.array(im)/255\n",
    "\n",
    "radius = int(np.ceil(np.sqrt(minPoints)))\n",
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(x0, imData, faults, water, radius) for x0 in tqdm(range(imData.shape[1])))\n",
    "\n",
    "x2_test = np.zeros((imData.shape[0]*imData.shape[1],2))\n",
    "count = 0\n",
    "count2 = 0\n",
    "index = []\n",
    "for x0 in result:\n",
    "    for elem in x0:\n",
    "        if elem[0] is not False:\n",
    "            x2_test[count2,:] = elem[0]\n",
    "            index.append(count)\n",
    "            count2+=1\n",
    "        count+=1\n",
    "\n",
    "x2_test2 = x_test.loc[x_test.index.isin(index)].reset_index(drop=True)\n",
    "x2_test2.insert(0,'Fault mean', x2_test[index,0]), x2_test2.insert(1,'Fault std', x2_test[index,1])\n",
    "x2_test2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralnetwork = myML.ANN()\n",
    "neuralnetwork.loadClass(name=\"training/heightmodel\")\n",
    "\n",
    "fullHeightmap = imData.copy()\n",
    "points = neuralnetwork.run(x2_test2)\n",
    "count = 0\n",
    "for x in range(fullHeightmap.shape[1]):\n",
    "    for y in range(fullHeightmap.shape[0]):\n",
    "        if imData[y,x]!=water: \n",
    "            fullHeightmap[y,x] = imData[y,x]\n",
    "            continue\n",
    "        fullHeightmap[y,x] = points[count,0]\n",
    "        count+=1\n",
    "\n",
    "imDepth = Image.fromarray(fullHeightmap)\n",
    "imDepth.save('output files/step2.png')\n",
    "display(imDepth.resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mountain peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakFinder(x0, imData):\n",
    "    temp = []\n",
    "    lims = imData.shape\n",
    "    for y0 in range(imData.shape[0]):\n",
    "        xlim = [max(0, x0-1), min(lims[1]-1, x0+1)]\n",
    "        ylim = [max(0, y0-1), min(lims[0]-1, y0+1)]\n",
    "\n",
    "        color = imData[y0,x0]\n",
    "        color = color-2 if color<127 else color*0.99\n",
    "\n",
    "        count = len(np.where(imData[ylim[0]:ylim[1]+1,xlim[0]:xlim[1]+1]>color)[0])\n",
    "        if count<=2: temp.append(255)\n",
    "        else: temp.append(0)\n",
    "\n",
    "    return temp\n",
    "\n",
    "heighttemp = np.array(Image.fromarray(fullHeightmap).resize((600,300)))\n",
    "peakData = np.empty_like(heighttemp)\n",
    "result = Parallel(n_jobs=-2)(delayed(peakFinder)(x0, heighttemp) for x0 in tqdm(range(heighttemp.shape[1])))\n",
    "\n",
    "for x0, res in enumerate(result):\n",
    "    for y0, value in enumerate(res):\n",
    "        peakData[y0,x0] = value\n",
    "\n",
    "Image.fromarray(peakData).save('output files/step3.png')\n",
    "display(Image.fromarray(peakData).resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erosion through Diffusion Limited Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakFinder(pos, fullHeightmap, simState):\n",
    "    lims = simState.shape\n",
    "    \n",
    "    ydown, yup = [max(0, pos[0]-1), min(lims[0]-1, pos[0]+1)]\n",
    "    xdown, xup = [max(0, pos[1]-1), min(lims[1]-1, pos[1]+1)]\n",
    "    #Check boundary for seed\n",
    "    if np.max(simState[ydown:yup+1,xdown:xup+1])>0: return [True, pos]\n",
    "\n",
    "    weights = [fullHeightmap[yup,x0]+1,fullHeightmap[y0,xup]+1,fullHeightmap[ydown,x0]+1,fullHeightmap[y0,xdown]+1]\n",
    "    paths = random.choices([0,1,2,3], weights=weights)[0]\n",
    "\n",
    "    if paths==0: pos[0] = yup\n",
    "    elif paths==1: pos[1] = xup\n",
    "    elif paths==2: pos[0] = ydown\n",
    "    else: pos[1] = xdown\n",
    "    return [False, pos]\n",
    "\n",
    "maxiter = 1000\n",
    "lookupRadius = 2\n",
    "diffused = peakData.copy()\n",
    "\n",
    "temp = np.where(diffused==0)\n",
    "total, voids, count = heighttemp.shape[0]*heighttemp.shape[1], len(temp[0]), heighttemp.shape[0]*heighttemp.shape[1]-len(temp[0])\n",
    "particles = int(np.sqrt(voids)*100)\n",
    "threshold1, threshold2 = int(np.sqrt(voids)*16), int(np.sqrt(voids)*4)\n",
    "nparticles = particles\n",
    "points = np.random.randint(0, voids, particles)\n",
    "points = [[temp[0][x],temp[1][x]] for x in points]\n",
    "\n",
    "bar_format='{desc}: |{bar}| {n_fmt}/{total_fmt} [t-{elapsed}, {postfix}]'\n",
    "pbar = tqdm(range(1,maxiter), desc='DLA', bar_format=bar_format)\n",
    "\n",
    "with Parallel(n_jobs=-2) as parallel:\n",
    "    for k in pbar:\n",
    "        if nparticles<20000:\n",
    "            result = []\n",
    "            for i in range(nparticles):\n",
    "                result.append(peakFinder(points[i], fullHeightmap, diffused))\n",
    "        else:\n",
    "            result = parallel(delayed(peakFinder)(points[i], fullHeightmap, diffused) for i in range(nparticles))\n",
    "\n",
    "        points = []\n",
    "        naggregated = count\n",
    "        temp = int(255*(1-(count/total)**(1/4)))\n",
    "        for i,elem in enumerate(result):\n",
    "            flag, pos = elem\n",
    "            if flag is True:\n",
    "                if diffused[pos[0],pos[1]]==0:\n",
    "                    count+=1\n",
    "                    diffused[pos[0],pos[1]] = temp\n",
    "            else: points.append(pos)\n",
    "\n",
    "        naggregated = count-naggregated\n",
    "        nparticles = len(points)\n",
    "        if nparticles<threshold1:\n",
    "            temp = np.where(diffused==0)\n",
    "            if len(temp[0]>threshold2):\n",
    "                points.extend([[temp[0][x],temp[1][x]] for x in np.random.randint(0, len(temp[0]), threshold2)])\n",
    "                nparticles+=threshold2\n",
    "        pbar.set_postfix_str(f'nparticles: {nparticles}, naggregated: {naggregated}, completion %%: {count/total*100:.2f}')\n",
    "        if nparticles==0: break\n",
    "    \n",
    "random.seed()\n",
    "\n",
    "# Application of gaussian blur with different radius to the diffused map + sum and normalization of the images\n",
    "blur_radius = [2,8,16,32,64]\n",
    "temp = sum([ndimage.gaussian_filter(diffused, sigma=r)/len(blur_radius) for r in blur_radius])\n",
    "diffused = np.round((temp-np.min(temp))*255/(np.max(temp)-np.min(temp))).astype(np.uint8)\n",
    "diffused = np.array(Image.fromarray(diffused).resize(imX.size, Image.Resampling.LANCZOS))\n",
    "Image.fromarray(diffused).save('output files/step4.png')\n",
    "display(Image.fromarray(diffused).resize((1200,600), Image.Resampling.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x, parameter):\n",
    "    return 1/(1+np.exp(-parameter*float(x-128)))\n",
    "\n",
    "parameter = 0.018\n",
    "\n",
    "erodedData = np.multiply(fullHeightmap,np.vectorize(func)(diffused, parameter)).astype(np.uint8)\n",
    "lims = np.min(erodedData[imData==0]), np.max(erodedData[imData==0]), np.min(erodedData[imData!=0]), np.max(erodedData[imData!=0])\n",
    "def func(x, y, a, b, c, d):\n",
    "    if y==0:\n",
    "        return 127*((x-a)/(b-a))\n",
    "    else:\n",
    "        return 128+127*((x-c)/(d-c))**2\n",
    "erodedData = np.round(np.vectorize(func)(erodedData, imData, lims[0],lims[1],lims[2],lims[3])).astype(np.uint8)\n",
    "blur_radius = [2,3,4]\n",
    "temp = sum([ndimage.gaussian_filter(erodedData, sigma=r)/len(blur_radius) for r in blur_radius])\n",
    "erodedData = np.round(temp).astype(np.uint8)\n",
    "display(Image.fromarray(erodedData).resize((1200,600), Image.Resampling.NEAREST))\n",
    "Image.fromarray(erodedData).save('output files/step5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watercolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_loop(y0,imData,erodedData,waterlims,landlims,equator,temperate_center,artic_center,intermediate,m):\n",
    "    temp2 = []\n",
    "    equator_distance = abs(m*(y0/imData.shape[0]-equator))+np.random.random()*0.01 #0 if at equator, 0.5 if at the poles \n",
    "    for x0 in range(imData.shape[1]):\n",
    "        height = erodedData[y0,x0]\n",
    "        \n",
    "        if height<128:\n",
    "            # Sea\n",
    "            height = height if height<waterlims[3] else waterlims[3]\n",
    "            if equator_distance<intermediate: \n",
    "                red = 0\n",
    "            else:\n",
    "                red = int(20*(equator_distance-intermediate)/(0.5-intermediate))\n",
    "\n",
    "            mingB = 0.73-0.17*equator_distance/0.5\n",
    "            max1gB = 1\n",
    "            max2gB = 1.25-0.25*(equator_distance/0.5)\n",
    "            minmod = 60-18*equator_distance/0.5\n",
    "            max1mod = 97-28*equator_distance/0.5\n",
    "            max2mod = 135-50*(equator_distance/0.5)\n",
    "\n",
    "            if height<=waterlims[1]:\n",
    "                modifier = ((height-waterlims[0])/(waterlims[1]-waterlims[0]))**2*0.5\n",
    "                heightmod = minmod+(max1mod-minmod)*modifier\n",
    "                gb = mingB+(max1gB-mingB)*modifier\n",
    "            elif height<=waterlims[2]:\n",
    "                modifier = ((height-waterlims[1])/(waterlims[2]-waterlims[1]))*0.5+0.5\n",
    "                heightmod = minmod+(max1mod-minmod)*modifier\n",
    "                gb = mingB+(max1gB-mingB)*modifier\n",
    "            else:\n",
    "                modifier = ((height-waterlims[2])/(waterlims[3]-waterlims[2]))\n",
    "                heightmod = max1mod+(max2mod-max1mod)*modifier\n",
    "                gb = max1gB+(max2gB-max1gB)*modifier\n",
    "            \n",
    "            blue = int(np.sqrt((heightmod**2-red**2)/(gb**2+1)))\n",
    "            green = int(gb*blue)\n",
    "        else:\n",
    "            # Land\n",
    "            height = height if height>landlims[0]+1 else landlims[0]+1\n",
    "            height = height if height<landlims[1] else landlims[1]\n",
    "            if equator_distance<artic_center: \n",
    "                red = int(50*(artic_center-equator_distance)/artic_center)\n",
    "            else:\n",
    "                red = 0\n",
    "            if equator_distance<=temperate_center:\n",
    "                temp = equator_distance/temperate_center\n",
    "                blue = 0\n",
    "                minmod = 56\n",
    "            else:\n",
    "                temp = (equator_distance-temperate_center)/(0.5-temperate_center)\n",
    "                blue = 74*temp\n",
    "                minmod = 56+35*temp\n",
    "            \n",
    "            maxmod = 77+49*equator_distance/0.5\n",
    "\n",
    "            modifier = ((height-landlims[0])/(landlims[1]-landlims[0]))**0.5\n",
    "            heightmod = minmod+(maxmod-minmod)*modifier\n",
    "            green = int(np.sqrt(heightmod**2-blue**2-red**2))\n",
    "            blue = int(blue)\n",
    "        temp2.append([red, green, blue])\n",
    "    return temp2\n",
    "\n",
    "equator = 0 #If 0 is the top, 1 the bottom, where is the equator in your map? The equation for m works with equator = 0, 0.5 or 1. Haven't done the math on the others, but you can ofc\n",
    "temperate_center = 0.2 #If 0 is the equator, 0.5 the pole. You want this between Gibraltar and the Pirinees, or equivalent in your mod\n",
    "artic_center = 0.36 #If 0 is the equator, 0.5 the pole. You want this around Helsinki in Finland, or equivalent in your mod\n",
    "\n",
    "temp = np.mean(erodedData[imData==0]), np.std(erodedData[imData==0])\n",
    "waterlims = np.min(erodedData[imData==0]), np.percentile(erodedData[imData==0],80), np.percentile(erodedData[imData==0],96),min(np.max(erodedData[imData==0]),127)\n",
    "temp = np.mean(erodedData[imData>0]), np.std(erodedData[imData>0])\n",
    "landlims = max(np.min(erodedData[imData>0]),128),np.max(erodedData[imData>0])\n",
    "\n",
    "m = 1-0.5*abs(equator-0.5)/(1-0.5)\n",
    "intermediate = (artic_center+temperate_center)/2\n",
    "watercolor = np.stack((erodedData.copy(),)*3, axis=-1)\n",
    "\n",
    "result = Parallel(n_jobs=-2)(delayed(inner_loop)(y0,imData,erodedData,waterlims,landlims,equator,temperate_center,artic_center,intermediate,m) for y0 in tqdm(range(imData.shape[0])))\n",
    "\n",
    "for y0, res in enumerate(result):\n",
    "    for x0, value in enumerate(res):\n",
    "        watercolor[y0,x0,:] = value\n",
    "    \n",
    "display(Image.fromarray(watercolor).resize((1200,600), Image.Resampling.NEAREST))\n",
    "Image.fromarray(watercolor).save('output files/watercolor_rgb_waterspec_a.png')\n",
    "print('Remember to convert it to dds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b22d928f5973cd7159b3034ea5d87b106ec4962028224788a5749e890f75777"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
